{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9_90nNKcAB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4e5f1c-bae7-416a-cac4-431e28053bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import sklearn \n",
        "from datetime import datetime\n",
        "import matplotlib as matplot \n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import sklearn.metrics \n",
        "import math\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "# !ls \"/content/gdrive/My Drive\"\n",
        "data_path = \"/content/gdrive/My Drive/Master ADS/Week 8/store-sales-time-series-forecasting/\"\n",
        "\n",
        "def print_results_metrics(truth_values, predicted_values):\n",
        "  print(\"RMSE: \", math.sqrt(sklearn.metrics.mean_squared_error(truth_values, predicted_values)))\n",
        "  print(\"MAD: \", np.mean(np.absolute(predicted_values - np.mean(predicted_values))))\n",
        "  print(\"MAE: \", sklearn.metrics.mean_absolute_error(truth_values, predicted_values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L97Xp5t0crd_"
      },
      "source": [
        "# Task 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUR5PVePcv3z"
      },
      "source": [
        "## Exercise 1\n",
        "Load oil.csv. This file contains years worth of data of the daily oil price. However, the data is missing for a few days. Make sure that every day contains a value using any data imputation technique that you learned during the data preparation week or during the missing values imputation week."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttfrgYVCcz3w",
        "outputId": "f8792377-bec2-4033-95cb-8d1cea63d83e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing values before: 43\n",
            "Number of missing values after: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "oil_data = pd.read_csv(data_path + \"oil.csv\")\n",
        "# checking missing values before applying imputation\n",
        "print(\"Number of missing values before: {}\".format(oil_data.isna().sum().sum()))\n",
        "oil_data = oil_data.fillna(oil_data.mean())\n",
        "# checking missing values before applying mean imputation \n",
        "print(\"Number of missing values after: {}\".format(oil_data.isna().sum().sum()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG0xX1hEesE2"
      },
      "source": [
        "## Exercise 2\n",
        "Augment the data in test.csv and train.csv with the oil price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXZ-GX43cpEy"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(data_path + \"train.csv\")\n",
        "test_data = pd.read_csv(data_path + \"test.csv\")\n",
        "ground_truth_df = pd.read_csv(data_path + \"submission.csv\")\n",
        "\n",
        "# train and test augmentation\n",
        "# fill the missing values with the mean\n",
        "# we have to do this because the oil.csv does not contain all the dates that train.csv has\n",
        "train_data = pd.merge(train_data, oil_data, on=['date'], how='left')\n",
        "train_data['dcoilwtico'].fillna(value = train_data['dcoilwtico'].mean(), inplace = True)\n",
        "test_data = pd.merge(test_data, oil_data, on=['date'], how='left')\n",
        "test_data['dcoilwtico'].fillna(value = test_data['dcoilwtico'].mean(), inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OlYnvaLbgBoY",
        "outputId": "8e36cc0c-b8c9-401c-b188-04b08ae5e6dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id        date  store_nbr        family  sales  onpromotion  dcoilwtico\n",
              "0   0  2013-01-01          1    AUTOMOTIVE    0.0            0   67.714366\n",
              "1   1  2013-01-01          1     BABY CARE    0.0            0   67.714366\n",
              "2   2  2013-01-01          1        BEAUTY    0.0            0   67.714366\n",
              "3   3  2013-01-01          1     BEVERAGES    0.0            0   67.714366\n",
              "4   4  2013-01-01          1         BOOKS    0.0            0   67.714366\n",
              "5   5  2013-01-01          1  BREAD/BAKERY    0.0            0   67.714366\n",
              "6   6  2013-01-01          1   CELEBRATION    0.0            0   67.714366\n",
              "7   7  2013-01-01          1      CLEANING    0.0            0   67.714366\n",
              "8   8  2013-01-01          1         DAIRY    0.0            0   67.714366\n",
              "9   9  2013-01-01          1          DELI    0.0            0   67.714366"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b3a8ec9-8a05-494f-a550-8a82fd25aede\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>store_nbr</th>\n",
              "      <th>family</th>\n",
              "      <th>sales</th>\n",
              "      <th>onpromotion</th>\n",
              "      <th>dcoilwtico</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>AUTOMOTIVE</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>67.714366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>BABY CARE</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>67.714366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>BEAUTY</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>67.714366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>BEVERAGES</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>67.714366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>BOOKS</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>67.714366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>BREAD/BAKERY</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>67.714366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>CELEBRATION</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>67.714366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>CLEANING</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>67.714366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>DAIRY</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>67.714366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>DELI</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>67.714366</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b3a8ec9-8a05-494f-a550-8a82fd25aede')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b3a8ec9-8a05-494f-a550-8a82fd25aede button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b3a8ec9-8a05-494f-a550-8a82fd25aede');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "hQgVw5VCgDnn",
        "outputId": "e7ffc27b-c727-48ee-b187-b7f6d14e8cff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id        date  store_nbr        family  onpromotion  dcoilwtico\n",
              "0  3000888  2017-08-16          1    AUTOMOTIVE            0        46.8\n",
              "1  3000889  2017-08-16          1     BABY CARE            0        46.8\n",
              "2  3000890  2017-08-16          1        BEAUTY            2        46.8\n",
              "3  3000891  2017-08-16          1     BEVERAGES           20        46.8\n",
              "4  3000892  2017-08-16          1         BOOKS            0        46.8\n",
              "5  3000893  2017-08-16          1  BREAD/BAKERY           12        46.8\n",
              "6  3000894  2017-08-16          1   CELEBRATION            0        46.8\n",
              "7  3000895  2017-08-16          1      CLEANING           25        46.8\n",
              "8  3000896  2017-08-16          1         DAIRY           45        46.8\n",
              "9  3000897  2017-08-16          1          DELI           18        46.8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb813d41-ddfb-4173-9dcd-da22ccfcc6a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>store_nbr</th>\n",
              "      <th>family</th>\n",
              "      <th>onpromotion</th>\n",
              "      <th>dcoilwtico</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3000888</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>1</td>\n",
              "      <td>AUTOMOTIVE</td>\n",
              "      <td>0</td>\n",
              "      <td>46.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3000889</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>1</td>\n",
              "      <td>BABY CARE</td>\n",
              "      <td>0</td>\n",
              "      <td>46.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3000890</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>1</td>\n",
              "      <td>BEAUTY</td>\n",
              "      <td>2</td>\n",
              "      <td>46.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3000891</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>1</td>\n",
              "      <td>BEVERAGES</td>\n",
              "      <td>20</td>\n",
              "      <td>46.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3000892</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>1</td>\n",
              "      <td>BOOKS</td>\n",
              "      <td>0</td>\n",
              "      <td>46.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3000893</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>1</td>\n",
              "      <td>BREAD/BAKERY</td>\n",
              "      <td>12</td>\n",
              "      <td>46.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3000894</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>1</td>\n",
              "      <td>CELEBRATION</td>\n",
              "      <td>0</td>\n",
              "      <td>46.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3000895</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>1</td>\n",
              "      <td>CLEANING</td>\n",
              "      <td>25</td>\n",
              "      <td>46.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3000896</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>1</td>\n",
              "      <td>DAIRY</td>\n",
              "      <td>45</td>\n",
              "      <td>46.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3000897</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>1</td>\n",
              "      <td>DELI</td>\n",
              "      <td>18</td>\n",
              "      <td>46.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb813d41-ddfb-4173-9dcd-da22ccfcc6a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb813d41-ddfb-4173-9dcd-da22ccfcc6a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb813d41-ddfb-4173-9dcd-da22ccfcc6a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "test_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXf4mgYLAnv2"
      },
      "source": [
        "## Exercise 3\n",
        "Note that the training set contains a ‘sales’ column while the test set doesnot.  Use the training set to train a model of your choice and use that model to  predict  which  values  for  sales  should  be  in  the  test  set.   You  can  try training multiple models and compare their accuracy later."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tranforming the data to a proper format"
      ],
      "metadata": {
        "id": "BqZtfgJevQph"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3-J9hoQl96c"
      },
      "outputs": [],
      "source": [
        "# instance of a label encoder\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# encoding family feature from train data\n",
        "train_data['family'] = label_encoder.fit_transform(train_data['family'])\n",
        "\n",
        "# encoding the family feature from test data\n",
        "test_data['family']= label_encoder.fit_transform(test_data['family'])\n",
        "\n",
        "# transforming the date to a numerical value\n",
        "train_data['date'] = train_data['date'].apply(lambda x: datetime.fromisoformat(x).timestamp())\n",
        "test_data['date'] = test_data['date'].apply(lambda x: datetime.fromisoformat(x).timestamp())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest model"
      ],
      "metadata": {
        "id": "W2jFtgSW6DD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate model\n",
        "rf_regressor = RandomForestRegressor(n_estimators = 5, random_state = 0)\n",
        "# Fit to training data\n",
        "rf_regressor.fit(train_data.drop('sales', axis=1), train_data['sales']) "
      ],
      "metadata": {
        "id": "Ynoq1Ddn6Fx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f53925-f338-40c7-e850-f870e0b0a70a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(n_estimators=5, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will make the predictions in the test set."
      ],
      "metadata": {
        "id": "hophoifA6Jm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on test set\n",
        "rf_prediction = rf_regressor.predict(test_data)"
      ],
      "metadata": {
        "id": "dk-MKaVi6Mas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBRegressor model\n",
        "\n",
        "Now we will make some changes in the data in order to be able to train a XGBRegressor model. "
      ],
      "metadata": {
        "id": "OBoXoaoD6TlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparation of the training data for XGBRegressor"
      ],
      "metadata": {
        "id": "y5g8Z1OQvfvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output of the training data\n",
        "y_train = np.array(train_data['sales'])\n",
        "# removing the columns that we dont need\n",
        "train_data = train_data.drop('id', axis = 1)\n",
        "train_data = train_data.drop('sales', axis = 1)\n",
        "\n",
        "# store the names of the features in a list\n",
        "feature_list = list(train_data.columns)\n",
        "X_train = np.array(train_data)\n",
        "print(\"Dimensions of the training set: {}\".format(X_train.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laRTWbOSnQS8",
        "outputId": "3309508b-8d27-43cd-edcb-652df7156ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of the training set: (3000888, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparation of the test data for XGBRegressor"
      ],
      "metadata": {
        "id": "NhL3_uSGv0C-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removing the columns that we dont need\n",
        "test_data = test_data.drop('id', axis = 1)\n",
        "\n",
        "# store the names of the features in a list\n",
        "feature_list = list(test_data.columns)\n",
        "X_test = np.array(test_data)\n",
        "print(\"Dimensions of the test set: {}\".format(X_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVqY66Ynn-g9",
        "outputId": "0982921d-e115-489e-d726-e2805d7cfa7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of the test set: (28512, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training XGBRegressor model"
      ],
      "metadata": {
        "id": "Vlfv_Ju5wdty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgB = XGBRegressor(n_estimators=30, objective='reg:squarederror')\n",
        "xgB.fit(X_train, y_train, verbose= False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb9oPf3umwDh",
        "outputId": "25676372-db25-4e0e-b35d-98c9c144ccdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(n_estimators=30, objective='reg:squarederror')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predicting values for the test set for XGBRegressor"
      ],
      "metadata": {
        "id": "uFYnvOEPwjor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgbr_predictions = xgB.predict(X_test)"
      ],
      "metadata": {
        "id": "b-59yyk3n87i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPHNFda7AX5F"
      },
      "source": [
        "## Exercise 4\n",
        "Compare your prediction with the prediction found in submission.csv with 3 different methods:\n",
        "\n",
        "*   Root Mean Square Error (RMSE)1\n",
        "*   Mean Absolute Deviation\n",
        "*   Anoher Metri of your choise\n",
        "\n",
        "Compare the three errors.  Are they in agreement?  Do you think any of themethods is objectively better than the others in this case?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "truth_values = np.array(ground_truth_df['sales'])"
      ],
      "metadata": {
        "id": "g86sXyvGw9W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for Random Forest"
      ],
      "metadata": {
        "id": "jXSo244D62fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comparing predicted values with ground truth and showing the metrics\n",
        "print_results_metrics(truth_values, rf_prediction)"
      ],
      "metadata": {
        "id": "_0T0oFlW63eg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c6a2ca-dfcd-4429-d745-d1500daa42bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE:  369.3718230551788\n",
            "MAD:  626.5673612382647\n",
            "MAE:  97.11466267240759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for GXBRegressor "
      ],
      "metadata": {
        "id": "CNiJ7q3I66Wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comparing predicted values with ground truth and showing the metrics\n",
        "print_results_metrics(truth_values, xgbr_predictions)"
      ],
      "metadata": {
        "id": "L8PazYc569Jv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d2dc25-6aea-49e0-fb57-66c77cb8abec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE:  720.8682103292491\n",
            "MAD:  523.2903\n",
            "MAE:  316.94458334800464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "We trained two models (XGBRegressor and Random Forest) in order to check wheter either of them could give better results. With the metrics shown above we can see that models perform differently in some situations. For example, Random Forest got a better RMSE and MAD, but XGBRegressor obtained a better MAE score. All 3 methods of measuring the predictions are in agreement because they are all positive values. The scale might not be the same because of the way of measuring the error in each method. Finally, we believe that it is hard to see if one method is objectively better than the others in this specific case. "
      ],
      "metadata": {
        "id": "mZ0fjbPsQ385"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2613xZVBVre"
      },
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLOhaAhJBale"
      },
      "source": [
        "## Exercise 1\n",
        "Determine which properties you want to consider privileged (e.g. age, gender,race, etc) and compute the following 3 fairness properties:  (Note that these 3 metrics do not require a trained model)\n",
        "\n",
        "* disparate impact ratio (DI ratio)\n",
        "* statistical parity difference (P. diff.)\n",
        "* consistency\n",
        "\n",
        "What do these numbers tell you about the fairness of the dataset?  Wouldyou say that the dataset is currently fair?  If not, what numbers would youneed to see to judge a dataset to be fair?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the required libraries\n",
        "!pip install sklearn\n",
        "!pip install aif360\n",
        "!pip install fairlearn\n",
        "!pip install sdv\n",
        "!pip install cgan\n",
        "!pip install imbalanced-learn\n",
        "!pip install scikit-learn==0.23.1\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zjVDUMn-Wn84",
        "outputId": "4c4bf776-93ae-493d-8859-5e272ffeb8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.23.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: aif360 in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.21.6)\n",
            "Collecting scikit-learn>=1.0\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 78.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360) (3.5.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360) (1.7.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->aif360) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->aif360) (3.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (4.38.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (21.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->aif360) (4.1.1)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.23.1\n",
            "    Uninstalling scikit-learn-0.23.1:\n",
            "      Successfully uninstalled scikit-learn-0.23.1\n",
            "Successfully installed scikit-learn-1.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fairlearn in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sdv in /usr/local/lib/python3.7/dist-packages (0.17.1)\n",
            "Requirement already satisfied: tqdm<5,>=4.15 in /usr/local/lib/python3.7/dist-packages (from sdv) (4.64.1)\n",
            "Requirement already satisfied: graphviz<1,>=0.13.2 in /usr/local/lib/python3.7/dist-packages (from sdv) (0.20.1)\n",
            "Requirement already satisfied: pandas<2,>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from sdv) (1.3.5)\n",
            "Requirement already satisfied: Faker<15,>=10 in /usr/local/lib/python3.7/dist-packages (from sdv) (14.2.1)\n",
            "Requirement already satisfied: ctgan<0.6,>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from sdv) (0.5.2)\n",
            "Requirement already satisfied: numpy<2,>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from sdv) (1.21.6)\n",
            "Requirement already satisfied: deepecho<0.4,>=0.3.0.post1 in /usr/local/lib/python3.7/dist-packages (from sdv) (0.3.0.post1)\n",
            "Requirement already satisfied: rdt<1.3.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from sdv) (1.2.1)\n",
            "Requirement already satisfied: sdmetrics<0.8,>=0.7.0.dev0 in /usr/local/lib/python3.7/dist-packages (from sdv) (0.7.0)\n",
            "Requirement already satisfied: copulas<0.8,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from sdv) (0.7.0)\n",
            "Requirement already satisfied: cloudpickle<3.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from sdv) (2.2.0)\n",
            "Requirement already satisfied: scipy<2,>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from copulas<0.8,>=0.7.0->sdv) (1.7.3)\n",
            "Requirement already satisfied: matplotlib<4,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from copulas<0.8,>=0.7.0->sdv) (3.5.3)\n",
            "Requirement already satisfied: torch<2,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from ctgan<0.6,>=0.5.2->sdv) (1.12.1+cu113)\n",
            "Requirement already satisfied: scikit-learn<2,>=0.24 in /usr/local/lib/python3.7/dist-packages (from ctgan<0.6,>=0.5.2->sdv) (1.0.2)\n",
            "Requirement already satisfied: packaging<22,>=20 in /usr/local/lib/python3.7/dist-packages (from ctgan<0.6,>=0.5.2->sdv) (21.3)\n",
            "Requirement already satisfied: torchvision<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from ctgan<0.6,>=0.5.2->sdv) (0.13.1+cu113)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.7/dist-packages (from Faker<15,>=10->sdv) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from Faker<15,>=10->sdv) (4.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (4.38.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>=1.1.3->sdv) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.4->Faker<15,>=10->sdv) (1.15.0)\n",
            "Requirement already satisfied: pyyaml<6,>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from rdt<1.3.0,>=1.2.0->sdv) (5.4.1)\n",
            "Requirement already satisfied: psutil<6,>=5.7 in /usr/local/lib/python3.7/dist-packages (from rdt<1.3.0,>=1.2.0->sdv) (5.9.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2,>=0.24->ctgan<0.6,>=0.5.2->sdv) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2,>=0.24->ctgan<0.6,>=0.5.2->sdv) (3.1.0)\n",
            "Requirement already satisfied: plotly<6,>=5.10.0 in /usr/local/lib/python3.7/dist-packages (from sdmetrics<0.8,>=0.7.0.dev0->sdv) (5.11.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly<6,>=5.10.0->sdmetrics<0.8,>=0.7.0.dev0->sdv) (8.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.2->sdv) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.2->sdv) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.2->sdv) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.2->sdv) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.2->sdv) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cgan (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for cgan\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all necessary packages\n",
        "import sys\n",
        "\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
        "\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
        "    import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
        "\n",
        "from aif360.algorithms.preprocessing.lfr import LFR\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "RqRWktqqXAXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988cf919-78fd-432f-df8b-ae993e0879ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
            "pip install 'aif360[LawSchoolGPA]'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_used = \"german\" \n",
        "protected_attribute_used = 2 # 1, 2\n",
        "if dataset_used == \"german\":\n",
        "    dataset_orig = GermanDataset()\n",
        "    if protected_attribute_used == 1:\n",
        "        privileged_groups = [{'sex': 1}]\n",
        "        unprivileged_groups = [{'sex': 0}]\n",
        "    else:\n",
        "        privileged_groups = [{'age': 1}]\n",
        "        unprivileged_groups = [{'age': 0}]\n",
        "        \n",
        "    for i in range(1000):\n",
        "        if (dataset_orig.labels[i] == 2.0):\n",
        "            dataset_orig.labels[i] = 0\n",
        "        else:\n",
        "            dataset_orig.labels[i] = 1\n",
        "        \n",
        "    dataset_orig.favorable_label = 1\n",
        "    dataset_orig.unfavorable_label = 0\n",
        "\n"
      ],
      "metadata": {
        "id": "PAhoREPJcJJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial disparities in the original datasets\n",
        "\n",
        "metric_orig = BinaryLabelDatasetMetric(dataset_orig, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "\n",
        "print(\"#### %s original dataset\\n\"%dataset_used)\n",
        "\n",
        "# Calculate the Disperate Impact Ratio\n",
        "print(\"Disparate impact (of original labels) between unprivileged and privileged groups = %f\" % metric_orig.disparate_impact())\n",
        "\n",
        "# Calculate the Statistical Parity Difference\n",
        "print(\"Difference in statistical parity (of original labels) between unprivileged and privileged groups = %f\" % metric_orig.statistical_parity_difference())\n",
        "\n",
        "# Calculate the Concisteny\n",
        "print(\"Individual fairness metric from Zemel et.al. that measures how similar the labels are for similar instances = %f\\n\" % metric_orig.consistency())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stNH3brAgAb3",
        "outputId": "7b172313-526b-4b45-85f2-1ae67b4fb897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#### german original dataset\n",
            "\n",
            "Disparate impact (of original labels) between unprivileged and privileged groups = 0.794826\n",
            "Difference in statistical parity (of original labels) between unprivileged and privileged groups = -0.149448\n",
            "Individual fairness metric from Zemel et.al. that measures how similar the labels are for similar instances = 0.681600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What do these numbers tell us? \n",
        "\n",
        "The disparate impact ratio is fair and legal when it's between 0.8 and 1.25, where 1 is optimal. Our DI is 0.794 which means that it is underneath 0.8 and thus not considered as fair by law.\n",
        "\n",
        "The statistical parity difference is considered as fair when it's close to zero. The difference in our dataset is 0.149 which is relatively close to the optimum but every value closer to 0 will be better. \n",
        "\n",
        "The consisteny is optimal when it's 1. The consisteny of our dataset is 0.68 which is not close to 1. \n",
        "\n",
        "Is our dataset fair? Not really. Since it is not fair by law and the consisteny is not close to 1. "
      ],
      "metadata": {
        "id": "VjgD7CsZnJIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2 \n",
        "\n",
        "Split the data into a 30/70 test and training set using stratification. Train a model using the training set and compute values the following 2 fairness\n",
        "metrics (in addition to the values of the previous 3 metrics (DI Ratio, P diff.\n",
        "and consistency)):\n",
        "* Equalized odds\n",
        "* Predictive parity\n",
        "\n",
        "What do these results tell you? Compute the accuracy of the model."
      ],
      "metadata": {
        "id": "S2wyrqlgmYjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting train and test set\n",
        "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
      ],
      "metadata": {
        "id": "NC4taAJCm2-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling the dataset\n",
        "scale_orig = StandardScaler()\n",
        "\n",
        "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
        "X_test = scale_orig.transform(dataset_orig_test.features)\n",
        "\n",
        "y_train = dataset_orig_train.labels.ravel()\n",
        "y_test = dataset_orig_test.labels.ravel()\n",
        "\n",
        "#Logistic Regression Training for each dataset\n",
        "log_reg = LogisticRegression() \n",
        "\n",
        "#Fitting the training set\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "#Predicting test set labels\n",
        "y_test_pred = log_reg.predict(X_test)\n",
        "y_test_pred_proba = log_reg.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "vw2nKOI9q00S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a new version of the test set with predicted class labels\n",
        "testset_pred = dataset_orig_test.copy()\n",
        "testset_pred.labels = y_test_pred\n",
        "\n",
        "#Construction 2\n",
        "#both original test dataset with actual labels and the test dataset combined with predicted class labels need to be given to this function\n",
        "classified_metric = ClassificationMetric(dataset_orig_test, \n",
        "                                                 testset_pred,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "\n",
        "#Checking Equalized Odds: average odds differecence, which is the avg. of differences in FPR&TPR for privileged and unprivileged groups.\n",
        "aeo = classified_metric.average_odds_difference()\n",
        "print(\"Average equalized odds difference between unprivileged and privileged groups = %f\" % aeo)\n",
        "\n",
        "#Predictive parity difference: PPV difference between privileged and unprivileged groups.\n",
        "ppd = classified_metric.positive_predictive_value(privileged=False) - classified_metric.positive_predictive_value(privileged=True)\n",
        "print(\"Predictive Parity difference between unprivileged and privileged groups = %f\" % ppd)"
      ],
      "metadata": {
        "id": "nq69RN-frSzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f271723-4ee8-443d-ad96-0cdd0858dab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average equalized odds difference between unprivileged and privileged groups = -0.214114\n",
            "Predictive Parity difference between unprivileged and privileged groups = -0.059045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Standard accuracy of logistic regression trained on German dataset without any mitigation = %f\" % classified_metric.accuracy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6cG1YrIw406",
        "outputId": "4ca24599-cae8-4899-e0c5-f39a4d1cb58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy of logistic regression trained on German dataset without any mitigation = 0.730000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What do these results tell us?\n",
        "\n",
        "\n",
        "In our model, the average equalized odds (AEO) is around 0.20. the AEO is optimal when it's 0. This means that there is a worse prediction for the sub groups and unfairness in the dataset. \n",
        "\n",
        "The accuracy of the model is 0.76"
      ],
      "metadata": {
        "id": "gxkENMVdwilD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3\n",
        "\n",
        "Use one of the bias mitigation algorithms that are implemented in aif360 to\n",
        "improve the model fairness and compute the fairness metrics values. How\n",
        "have the values of all 5 fairness properties changed? Compute the accuracy\n",
        "and compare the value with the obtained in the previous question."
      ],
      "metadata": {
        "id": "7lP7O-ID2Ds9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.algorithms.preprocessing.lfr import LFR\n",
        "\n",
        "\n",
        "# LFR itself contains logistic regression since it uses sigmoid functions \n",
        "lfr_obj =LFR(unprivileged_groups=unprivileged_groups,\n",
        "         privileged_groups=privileged_groups,\n",
        "         k=5, Ax=0.01, Ay=1.0, Az=50.0, verbose=1)\n",
        "\n",
        "TR = lfr_obj.fit(dataset_orig_train, maxiter=5000, maxfun=5000)\n",
        "\n",
        "\n",
        "#scaled dataset together with its labels is needed\n",
        "dataset_orig_train.features = scale_orig.fit_transform(dataset_orig_train.features)\n",
        "dataset_orig_test.features = scale_orig.transform(dataset_orig_test.features)\n",
        "\n",
        "\n",
        "# Transform training data and align features\n",
        "dataset_transf_train = TR.transform(dataset_orig_train)\n",
        "# Before proceeding to the next step, make sure that LFR doesn't solve the bias\n",
        "# using the trivial solution (converting all the labels to the preferable label)\n",
        "from collections import Counter\n",
        "c = Counter(dataset_transf_train.labels.ravel())\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbex_bFu2QZr",
        "outputId": "1955dbad-e7c0-4072-9e59-8fc846b279d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, loss: 6306.8327353958175, L_x: 630620.2621563061,  L_y: 0.627652866573587,  L_z: 4.9219323653626466e-05\n",
            "step: 250, loss: 6306.832735396124, L_x: 630620.2621563952,  L_y: 0.6276528664367913,  L_z: 4.921931470349694e-05\n",
            "step: 500, loss: 6305.688914415635, L_x: 630507.5904722863,  L_y: 0.6109794377948053,  L_z: 4.060509952453217e-05\n",
            "step: 750, loss: 6305.594447199212, L_x: 630498.113067416,  L_y: 0.6113200359297114,  L_z: 3.992978243891054e-05\n",
            "step: 1000, loss: 6303.501273318389, L_x: 630287.8578050908,  L_y: 0.621512963465458,  L_z: 2.3646080306716223e-05\n",
            "step: 1250, loss: 6292.369638148416, L_x: 629170.2540122072,  L_y: 0.6670571225434677,  L_z: 8.180760267831756e-07\n",
            "step: 1500, loss: 6252.162321508862, L_x: 625146.0543736017,  L_y: 0.701777768895753,  L_z: 7.898601707141879e-11\n",
            "step: 1750, loss: 6252.162321508862, L_x: 625146.0543736017,  L_y: 0.7017777688957534,  L_z: 7.898569671203005e-11\n",
            "step: 2000, loss: 6246.6065493795, L_x: 624585.623529826,  L_y: 0.7503140802095247,  L_z: 2.0606580450296185e-11\n",
            "step: 2250, loss: 6246.401675034555, L_x: 624119.7146284909,  L_y: 5.204528749515158,  L_z: 2.6295851715744007e-12\n",
            "step: 2500, loss: 6246.60626838619, L_x: 624585.5986193798,  L_y: 0.7502821913613327,  L_z: 2.0609422992898832e-11\n",
            "step: 2750, loss: 6244.13792962485, L_x: 624352.6162819872,  L_y: 0.6117668046097703,  L_z: 7.368718732959215e-12\n",
            "step: 3000, loss: 6220.181908320987, L_x: 620936.8812304251,  L_y: 10.813096016735146,  L_z: 8.328461566950572e-19\n",
            "step: 3250, loss: 6220.181908320987, L_x: 620936.8812304251,  L_y: 10.813096016735146,  L_z: 8.328485177616014e-19\n",
            "step: 3500, loss: 6244.132263333159, L_x: 624352.049209714,  L_y: 0.6117712356504332,  L_z: 7.348589968694244e-12\n",
            "step: 3750, loss: 6227.117876634045, L_x: 622642.2952562518,  L_y: 0.6949240715266702,  L_z: 4.052594884404148e-15\n",
            "step: 4000, loss: 6216.000595921095, L_x: 621504.8405370493,  L_y: 0.9521905506014462,  L_z: 1.4985457872316017e-15\n",
            "step: 4250, loss: 6212.521226020962, L_x: 621126.2083211516,  L_y: 1.259142809446385,  L_z: 1.9611079601025796e-18\n",
            "step: 4500, loss: 3828.607507726485, L_x: 381755.3942123669,  L_y: 10.543952674770008,  L_z: 0.010192258560916306\n",
            "step: 4750, loss: 5470.2437573232055, L_x: 546889.9271834907,  L_y: 1.3444854882981807,  L_z: 7.473115708841547e-37\n",
            "step: 5000, loss: 5470.2437573232055, L_x: 546889.9271834907,  L_y: 1.3444854882981807,  L_z: 7.473115435983231e-37\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0.0: 424, 1.0: 276})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
        "                                             unprivileged_groups = unprivileged_groups,\n",
        "                                             privileged_groups = privileged_groups)"
      ],
      "metadata": {
        "id": "o7fMBIfe4JSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the Disperate Impact Ratio\n",
        "print(\"Disparate impact (of original labels) between unprivileged and privileged groups = %f\" % metric_transf_train.disparate_impact())\n",
        "\n",
        "# Calculate the Statistical Parity Difference\n",
        "print(\"Difference in statistical parity (of original labels) between unprivileged and privileged groups = %f\" % metric_transf_train.statistical_parity_difference())\n",
        "\n",
        "# Calculate the Concisteny\n",
        "print(\"Individual fairness metric from Zemel et.al. that measures how similar the labels are for similar instances = %f\\n\" % metric_transf_train.consistency())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRxg3j2I3DUd",
        "outputId": "62439409-0d9d-49f3-e07d-7e2f37ff683f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disparate impact (of original labels) between unprivileged and privileged groups = 0.874971\n",
            "Difference in statistical parity (of original labels) between unprivileged and privileged groups = -0.050497\n",
            "Individual fairness metric from Zemel et.al. that measures how similar the labels are for similar instances = 0.983429\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If the counter in the previous cell shows more than one class, proceed to this step \n",
        "# Otherwise, you cannot train model\n",
        "\n",
        "\n",
        "X_train_trans =dataset_transf_train.features\n",
        "X_test_trans = dataset_orig_test.features\n",
        "\n",
        "y_train_trans = dataset_transf_train.labels.ravel()\n",
        "y_test_trans = dataset_orig_test.labels.ravel() \n",
        "\n",
        "\n",
        "#Logistic Regression Training with the transformed dataset\n",
        "trans_lr = LogisticRegression(solver='liblinear')\n",
        "\n",
        "#fitting the model\n",
        "trans_lr.fit(X_train_trans, y_train_trans)\n",
        "\n",
        "#Predicting test set labels\n",
        "y_test_trans_pred = trans_lr.predict(X_test_trans)\n",
        "y_test_trans_pred_proba = trans_lr.predict_proba(X_test_trans)"
      ],
      "metadata": {
        "id": "EdzNoqcx7hHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new version of the transformed test set with predicted class labels\n",
        "testset_pred_trans = dataset_orig_test.copy()\n",
        "testset_pred_trans.labels = y_test_trans_pred"
      ],
      "metadata": {
        "id": "64FvLm9h8cA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_trans_test = BinaryLabelDatasetMetric(testset_pred_trans, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "classified_trans_test = ClassificationMetric(dataset_orig_test, \n",
        "                                                 testset_pred_trans,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "\n",
        "\n",
        "#Disparate Impact ratio between privileged and unprivileged groups.\n",
        "deb_di_t = classified_trans_test.disparate_impact()\n",
        "print(\"Disparate impact ratio between unprivileged and privileged groups = %f\" % deb_di_t)\n",
        "\n",
        "#Statistical parity difference between privileged and unprivileged groups.\n",
        "deb_spd_t = classified_trans_test.statistical_parity_difference()\n",
        "print(\"Statistical parity difference between unprivileged and privileged groups = %f\" % deb_spd_t)\n",
        "\n",
        "#Individual Fairness: 1)Consistency, 2) Euclidean Distance between individuals.\n",
        "print(\"Consistency of indivuals' predicted labels = %f\" % metric_trans_test.consistency())\n",
        "\n",
        "#Predictive parity difference: PPV difference between privileged and unprivileged groups.\n",
        "deb_ppd_t = classified_trans_test.positive_predictive_value(privileged=False) - classified_trans_test.positive_predictive_value(privileged=True)\n",
        "print(\"Predictive Parity difference between unprivileged and privileged groups = %f\" % deb_ppd_t)\n",
        "\n",
        "#Checking Equalized Odds: average odds differecence, which is the avg. of differences in FPR&TPR for privileged and unprivileged groups.\n",
        "deb_aeo_t = classified_trans_test.average_odds_difference()\n",
        "print(\"Average equalized odds difference between unprivileged and privileged groups = %f\" % deb_aeo_t)\n",
        "\n",
        "\n",
        "print(\"Standard accuracy of logistic regression trained on test set with debiasing = %f\" % classified_trans_test.accuracy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yom6QnMr8k_1",
        "outputId": "e116bb4a-b80e-4afa-b32f-1d46f1564e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disparate impact ratio between unprivileged and privileged groups = 1.299248\n",
            "Statistical parity difference between unprivileged and privileged groups = 0.129305\n",
            "Consistency of indivuals' predicted labels = 0.762667\n",
            "Predictive Parity difference between unprivileged and privileged groups = -0.168155\n",
            "Average equalized odds difference between unprivileged and privileged groups = 0.148181\n",
            "Standard accuracy of logistic regression trained on test set with debiasing = 0.503333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare the values\n",
        "\n",
        "Now we can compare the values of the data before mitigation and the data after mitigation. \n",
        "\n",
        "**Disparate Impact Ratio**\n",
        "\n",
        "* Before Bias Mitigation: 0.794826\n",
        "* After Bias Mitigation: 0.798922\n",
        "\n",
        "**Statistical Parity Difference**\n",
        "* Before Bias Mitigation: -0.149448\n",
        "* After Bias Mitigation: -0.113971\n",
        "\n",
        "**Consistency**\n",
        "* Before Bias Mitigation: 0.681600\n",
        "* After Bias Mitigation: 0.75400\n",
        "\n",
        "**Equalized odds**\n",
        "* Before Bias Mitigation: -0.076385\n",
        "* After Bias Mitigation: -0.1199389\n",
        "\n",
        "**Predictive Parity Distance**\n",
        "* Before Bias Mitigation: -0.210636\n",
        "* After Bias Mitigation: -0.214286\n",
        "\n",
        "**Accuracy**\n",
        "* Before Bias Mitigation: 0.763333\n",
        "* After Bias Mitigation: 0.503\n",
        "\n",
        "The accuracy of the model decreased by almost 0.26.\n",
        "\n",
        "The performance of the DI, SPD and consistency increased. This means that the fairness of the dataset slightly increased by watching these values. \n",
        "\n",
        "If we look to Equalized odds and preditive parity distance, the fairness decreased."
      ],
      "metadata": {
        "id": "rW4cYUgy_O9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4\n",
        "Synthesise a new dataset by oversampling the underrepresented classes. For\n",
        "this, you can use any technique discussed in the lecture such as SMOTE or\n",
        "GANs. Train the model in exactly the same way (as you did in Exercise 2)\n",
        "on this new dataset. How have the values of all 5 fairness measures changed?\n",
        "Compute the accuracy of the model and compare the value with the accuracy\n",
        "value that was obtained in question 2."
      ],
      "metadata": {
        "id": "FTeBoG38PyZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "german_data = GermanDataset()\n",
        "c = Counter(german_data.labels.ravel())\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV4UvTslnti7",
        "outputId": "ea15eeb8-b98d-4fd3-f2ef-4f07236b631f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1.0: 700, 2.0: 300})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "gfNFyo8HoFD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use SMOTE to oversample the underrepresented class\n",
        "oversample = SMOTE()\n",
        "X_OS, y_OS = oversample.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "9Q9VcY3NoIEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression fit to oversampled data\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_OS, y_OS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZuetDjwoKA3",
        "outputId": "b6cce94e-efd6-4610-d5e2-e20eec36deb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_smote_pred = logreg.predict(X_test)\n",
        "\n",
        "testset_pred_smote = dataset_orig_test.copy()\n",
        "testset_pred_smote.labels = y_test_smote_pred"
      ],
      "metadata": {
        "id": "cq0EYLDKoMwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_transf_train = BinaryLabelDatasetMetric(testset_pred_smote, \n",
        "                                             unprivileged_groups = unprivileged_groups,\n",
        "                                             privileged_groups = privileged_groups)\n",
        "\n",
        "classified_metric = ClassificationMetric(dataset_orig_test, \n",
        "                                                 testset_pred_smote,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Disparate impact ratio (of transformed labels) between unprivileged and privileged groups = %f\" % metric_transf_train.disparate_impact())\n",
        "print(\"Difference in statistical parity (of transformed labels) between unprivileged and privileged groups = %f\" % metric_transf_train.statistical_parity_difference())\n",
        "print(\"Individual fairness metric 'consistency' that measures how similar the labels are for similar instances = %f\" % metric_transf_train.consistency())\n",
        "ppd = classified_metric.positive_predictive_value(privileged=False) - classified_metric.positive_predictive_value(privileged=True)\n",
        "print(\"Predictive Parity difference between unprivileged and privileged groups = %f\" % ppd)\n",
        "aeo = classified_metric.average_odds_difference()\n",
        "print(\"Average equalized odds difference between unprivileged and privileged groups = %f\" % aeo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJfk12BboPm3",
        "outputId": "cc9f0f50-356e-470b-e6ab-0c607d71cbee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disparate impact ratio (of transformed labels) between unprivileged and privileged groups = 0.587142\n",
            "Difference in statistical parity (of transformed labels) between unprivileged and privileged groups = -0.283734\n",
            "Individual fairness metric 'consistency' that measures how similar the labels are for similar instances = 0.767333\n",
            "Predictive Parity difference between unprivileged and privileged groups = -0.079667\n",
            "Average equalized odds difference between unprivileged and privileged groups = -0.207331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: %.3f\" % accuracy_score(y_test, y_test_smote_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGedMyYSoSRJ",
        "outputId": "1488e14c-0a3c-4278-8a08-51e54c96a2d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What changed when using SMOTE?\n",
        "\n",
        "so, basically the fairness of the dataset decreased when using SMOTE which is quite intresting since we expected the opposite. \n",
        "\n",
        "The accuracy of the model is 0.747. The accuracy of the model in question 2 is 0.73. This means that the accuracy slightly increased when using SMOTE.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JypCgOaoqphv"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}